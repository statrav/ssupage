---
title: ""
subtitle: ""
description: ""
author: "Hyesu Hwang"
date: "2024-08-15"
categories: [Pytorch, Text, RAG, OpenSourceLM]
open-graph:
  description: ""
  image: ../images/2_ambig/thumbnail.png
---

## ⭐프로젝트 소개

- 기간: 2024. 01 - 2024. 08
- 프로젝트명: 특정 상황에 대한 RAG의 한계 분석 연구
- 한 줄 소개: 잘못된 가정을 포함하고 있는 모호한 Query에 대한 RAG의 성능 문제를 발견하고, Query 분해를 통해 문제를 해결합니다.


## 💎왜 이 프로젝트가 중요한가?



## 🔎핵심 기술은 무엇인가?

#### 사용 기술
- Llama-2-7b-chat-hf
- ElasticSearch
- BM25

## 🌄어떠한 시행착오를 겪었는가?



1. 왜 중요한가?
문제 제기: 대규모 언어 모델(LLM)은 학습 데이터 바깥의 지식 접근이 어렵고, 사용자의 모호하거나 잘못된 전제를 포함한 질문에 의해 성능이 저하될 수 있습니다. RAG(Retrieval-Augmented Generation) 기법은 외부 지식을 검색해 이를 LLM에 제공하여 성능 향상을 목표로 하지만, 기존 연구들은 모호한 질문이 검색 단계에서 부정적인 영향을 미친다는 점을 충분히 다루지 않았습니다.
목표: RAG 환경에서 모호한 질문이 검색 단계에 미치는 악영향을 분석하고, 이를 개선하여 LLM의 성능을 높이는 방법론을 제안하는 것이 본 연구의 목표입니다.
2. 핵심 기술은 무엇인가?
질문 분해(Query Decomposition): 사용자의 모호한 질문을 여러 하위 질문으로 나누고, 각각의 하위 질문에 대해 외부 지식을 검색하는 방법입니다. 이로 인해 LLM이 보다 명확하고 관련성 높은 정보를 바탕으로 답변을 생성할 수 있게 됩니다.
RAG 환경에서의 적용: 검색 기반 생성(RAG) 모델에서 기존의 단일 검색이 아닌, 하위 질문에 기반한 다중 검색을 수행하여 잡음을 줄이고 성능을 향상시키는 방법을 제시했습니다.
3. 어떠한 인사이트로부터 시작하였는가?
기존 RAG 모델의 한계: 초기 실험에서 RAG를 단순 적용할 경우, 오히려 성능이 낮아지는 현상이 관찰되었습니다. 이는 검색된 정보가 부정확하거나 불필요한 잡음을 포함해 LLM의 성능을 저하시킨다는 점을 발견하게 했습니다.
모호한 질문의 영향: 모호한 질문이 검색 단계에서 부적절한 정보를 검색하게 만드는 주요 원인이며, 이를 해결하기 위해 질문 자체를 명확히 하고 쪼개는 방법이 필요하다는 인사이트에서 시작했습니다.
4. 시행착오 및 결과
시행착오: 초기에는 RAG가 단순히 외부 지식을 제공하는 것만으로도 성능 향상을 가져올 것이라고 가정했습니다. 그러나, 단일 검색 결과를 적용했을 때 LLM 성능이 오히려 떨어지는 것을 확인하면서, 검색 단계에서의 잡음 문제를 해결하기 위해 다양한 질문 분해 방법을 실험했습니다.
결과: 질문 분해를 적용한 RAG 방식이 단순 RAG와 비-RAG 방식에 비해 F1 스코어 기준으로 QAQA와 HotpotQA 데이터셋에서 높은 성능을 보였습니다. 이는 제안된 방법이 모호한 질문의 문제를 효과적으로 해결할 수 있음을 입증했으며, 다중 단계 질문에서도 성능 개선이 가능하다는 점을 확인했습니다.

두 가지 주요 단계로 나뉩니다.

첫째, 질문 분해 단계에서 사용자의 입력 질문을 여러 하위 질문으로 나누며, 이를 위해 LLM에 적절한 프롬프트를 제공합니다.
둘째, 답변 생성 단계에서 하위 질문으로부터 검색된 추가적인 맥락 정보를 바탕으로 LLM이 최종 답변을 생성하도록 합니다.

이 알고리즘은 RAG에서 이전에 다루지 않은 문제를 효과적으로 해결할 수 있는 간단한 접근법을 제시합니다.



